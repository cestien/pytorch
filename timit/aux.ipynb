{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f926fa",
   "metadata": {},
   "source": [
    "# Notebook auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae35e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "from matplotlib import pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824a532",
   "metadata": {},
   "source": [
    "#### La función `collate_fn` (para construir minibatches con datos de diferente longitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a4fcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 9, 8, 8]) tensor(1)\n",
      "tensor([5, 1, 3, 3, 8, 2, 3, 1, 0, 0]) tensor(1)\n",
      "tensor([6, 0, 5, 8, 8, 6, 2, 8]) tensor(1)\n",
      "tensor([5, 6, 1, 3, 8, 6]) tensor(1)\n",
      "tensor([7, 8, 3, 3, 4, 9, 6, 7, 2, 8, 7, 1]) tensor(0)\n",
      "\n",
      "Batch 1:\n",
      "Padded Sequences:\n",
      "tensor([[2, 0, 9, 8, 8, 0, 0, 0, 0, 0],\n",
      "        [5, 1, 3, 3, 8, 2, 3, 1, 0, 0]])\n",
      "Labels:\n",
      "tensor([1, 1])\n",
      "Shape of padded sequences:\n",
      "torch.Size([2, 10])\n",
      "Batch 2:\n",
      "Padded Sequences:\n",
      "tensor([[6, 0, 5, 8, 8, 6, 2, 8],\n",
      "        [5, 6, 1, 3, 8, 6, 0, 0]])\n",
      "Labels:\n",
      "tensor([1, 1])\n",
      "Shape of padded sequences:\n",
      "torch.Size([2, 8])\n",
      "Batch 3:\n",
      "Padded Sequences:\n",
      "tensor([[7, 8, 3, 3, 4, 9, 6, 7, 2, 8, 7, 1]])\n",
      "Labels:\n",
      "tensor([0])\n",
      "Shape of padded sequences:\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class VariableLengthDataset(Dataset):\n",
    "    def __init__(self): # Inventamos un dataset de longitud variable\n",
    "        self.data = [\n",
    "            torch.randint(0, 10, (length,)) for length in [5, 10, 8, 6, 12]\n",
    "        ]\n",
    "        self.labels = torch.randint(0, 2, (len(self.data),))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # El batch es una lista de tuplas: [(dato1,label1), (dato2,label2),...]\n",
    "    sequences, labels = zip(*batch) # Esto devuelve: \n",
    "                                    # sequences = (dato1,dato2,...)\n",
    "                                    # labels = (label1,label2,...)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    return padded_sequences, labels # Esta es la salida del dataloader\n",
    "\n",
    "dataset = VariableLengthDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    dato,label =  dataset[i]\n",
    "    print(dato,label)\n",
    "print()\n",
    "\n",
    "for batch_idx, (padded_sequences, labels) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(\"Padded Sequences:\")\n",
    "    print(padded_sequences)\n",
    "    print(\"Labels:\")\n",
    "    print(labels)\n",
    "    print(\"Shape of padded sequences:\")\n",
    "    print(padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0f629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 9, 8, 8]) tensor(1)\n",
      "tensor([5, 1, 3, 3, 8, 2, 3, 1, 0, 0]) tensor(1)\n",
      "tensor([6, 0, 5, 8, 8, 6, 2, 8]) tensor(1)\n",
      "tensor([5, 6, 1, 3, 8, 6]) tensor(1)\n",
      "tensor([7, 8, 3, 3, 4, 9, 6, 7, 2, 8, 7, 1]) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    dato,label =  dataset[i]\n",
    "    print(dato,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4980f4",
   "metadata": {},
   "source": [
    "##### Sobre `zip` y el operador `*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb68f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b c\n",
      "a b c\n",
      "('x', 'y', 'z')\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Si pasamos una lista como argumento a una función y le aplicamos el operador * a dicha lista,\n",
    "# el operador \"desarma\" la lista y la convierte en argumentos separados para la función\n",
    "x = ['a','b', 'c']\n",
    "print(*x)\n",
    "print(x[0],x[1],x[2])\n",
    "\n",
    "# zip es un iterador de tuplas:\n",
    "# tuplas de entrada: [(a,1),(b,2),(c,3)]\n",
    "# tuplas de salida: ([a,b,c),(1,2,3)]\n",
    "l = [('x',1),('y',2),('z',3)]\n",
    "ll = zip(*l)\n",
    "for i in ll:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf0959",
   "metadata": {},
   "source": [
    "##### Sobre tteradores e iterables\n",
    "  - Un iterable es cualquier objeto que se pueda recorrer o *iterar*, por ejemplo una lista, una tupla, un rango, un diccionario. \n",
    "  - Un iterador es un objeto que implementa el protocolo de *iterador*, es decir, un objeto que tiene definidos los métodos:\n",
    "    - `__iter__` que devuelve el propio objeto iterador\n",
    "    - `__next__` que devuelve el siguiente elemento de la secuencia y un `StopIteration` cuando la secuencia llegó a su fin\n",
    "  - La estructura de control `for`:\n",
    "    - recibe un iterable, por ejemplo `range(10)`\n",
    "    - le aplica `iter()` con lo cual lo convierte en iterador\n",
    "    - llama repetidamente a `next()` hasta que aparezca la excepción `StopIteration` y termina\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ebf199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [1,2,3,4,5] # L es un iterable\n",
    "iter_L = iter(L) # iter_L es un iterador\n",
    "next(iter_L) # Devuelve el primer elemento del iterador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d527e3",
   "metadata": {},
   "source": [
    "##### Sobre los generadores\n",
    "Un generador es un objeto de tipo iterador creado por:\n",
    "  - *Una función generadora*. Es decir, una función que devuelve sus resultados usando `yield` en lugar de `return`. Esto hace que la función recuerde el estado cuando se la deja y lo retome cuando se la llame de nuevo. \n",
    "  - *Una expresión generadora*. Es igual que la comprehension list solo que se usan paréntesis en lugar de corchetes.\n",
    "\n",
    "Ojo, no todo objeto de tipo iterador es un objeto generador, solo los que son creados por una función generadora.\n",
    "\n",
    "También se podría crear un generador como instancia de una clase siempre que dicha tenga implementado los métodos `__iter__` y `__next__` para convertirla en iterador y los elementos del objeto sean creados con un método generador, es decir una función de que devuelva mediante `yield`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d62969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "0 2\n"
     ]
    }
   ],
   "source": [
    "# Función generadora\n",
    "def even_numbers(limit):\n",
    "    num = 0\n",
    "    while num < limit:\n",
    "        yield num\n",
    "        num += 2\n",
    "gen_even = even_numbers(10) # gen_even es un generador\n",
    "for n in even_numbers(10):\n",
    "    print(n)\n",
    "\n",
    "print(next(gen_even),next(gen_even)) # Devuelve el siguiente elemento del generador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76d42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Expresión generadora\n",
    "gen_even = (num for num in range(10) if num % 2 == 0) \n",
    "for n in gen_even:\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96740af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "<class '__main__.NumerosCuadrados'>\n"
     ]
    }
   ],
   "source": [
    "# Clase que se comporta como un iterador\n",
    "class NumerosCuadrados:\n",
    "    def __init__(self, limite):\n",
    "        self.limite = limite\n",
    "        self.actual = 0 # Maneja el estado\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self # Un iterador es un iterable que se devuelve a sí mismo\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.actual < self.limite:\n",
    "            valor = self.actual * self.actual\n",
    "            self.actual += 1 # Actualiza el estado para la próxima llamada\n",
    "            return valor\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "# Uso de la clase iterador\n",
    "cuadrados_obj = NumerosCuadrados(5)\n",
    "\n",
    "for num in cuadrados_obj:\n",
    "    print(num)\n",
    "\n",
    "print(type(cuadrados_obj)) # Salida: <class '__main__.NumerosCuadrados'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c1965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Clase que contiene un método generador\n",
    "# Para iterar con una instancia de esta \n",
    "# clase no es necesario implementar los métodos __iter__ y __next__\n",
    "# porque el método generador ya lo hace implícitamente ya que todo generador es un iterador.\n",
    "class SecuenciaPersonalizada:\n",
    "    def __init__(self, inicio, fin):\n",
    "        self.inicio = inicio\n",
    "        self.fin = fin\n",
    "\n",
    "    def generar_rango(self): # Esto es un método generador\n",
    "        actual = self.inicio\n",
    "        while actual <= self.fin:\n",
    "            yield actual\n",
    "            actual += 1\n",
    "\n",
    "# Uso de la clase con un método generador\n",
    "mi_secuencia = SecuenciaPersonalizada(1, 5)\n",
    "\n",
    "# Llamar al método generador para obtener un objeto generador\n",
    "gen_obj = mi_secuencia.generar_rango()\n",
    "\n",
    "print(type(gen_obj)) # Salida: <class 'generator'>\n",
    "\n",
    "for num in gen_obj:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9b384",
   "metadata": {},
   "source": [
    "##### Diferencia entre generadores y clases/instancias\n",
    "  - Clases/Instancias: Mantienen el estado de los datos (variables de instancia) a través de múltiples llamadas a sus métodos. Los métodos, a menos que usen yield, se ejecutan de forma completa cada vez.\n",
    "  - Generadores: Mantienen el estado de la ejecución (variables locales, punto de pausa) y permiten \"pausar\" y \"reanudar\" la ejecución de la función.\n",
    "\n",
    "Puedes tener métodos de clase que sean generadores (si contienen yield), pero esto es una elección de diseño específica y no una propiedad inherente de todos los métodos de clase.\n",
    "\n",
    "Recordar que `__iter__` siempre debe devolver un objeto de tipo iterador. En el siguiente ejemplo esto lo hacemos devolviendo con `yield` ya que de este modo se convierte a `__iter__` en una función generadora y por lo tanto devolverá un iterador (de tipo generador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f83fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-2\n",
      "-3\n",
      "-4\n",
      "-5\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "class Prueba():\n",
    "    def __init__(self, x):\n",
    "        self.x = a\n",
    "\n",
    "    def __iter__(self):\n",
    "    #    return self.x\n",
    "        for i in self.x:\n",
    "            yield  -i\n",
    "p = Prueba(a)\n",
    "\n",
    "for i in p:\n",
    "    print(i)  # Salida: 1, 2, 3, 4, 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe183d",
   "metadata": {},
   "source": [
    "##### La función `stack` (unión de tensores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f4f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "  \n",
    "# creating tensors \n",
    "x = torch.tensor([1.,3.,6.,10.]) \n",
    "y = torch.tensor([2.,7.,9.,13.]) \n",
    "# printing above created tensors \n",
    "print(\"Tensor x:\", x) \n",
    "print(\"Tensor y:\", y) \n",
    "  \n",
    "# join above tensor using \"torch.stack()\" \n",
    "print(\"join tensors:\") \n",
    "t = torch.stack((x,y)) \n",
    "  \n",
    "# print final tensor after join \n",
    "print(t) \n",
    "\n",
    "\n",
    "print(\"join tensors dimension 0:\") \n",
    "t = torch.stack((x,y), dim = 0) \n",
    "print(t) \n",
    "  \n",
    "print(\"join tensors dimension 1:\") \n",
    "t = torch.stack((x,y), dim = 1) \n",
    "print(t) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aca08a",
   "metadata": {},
   "source": [
    "#### Reproducibilidad de los experimentos\n",
    "Como fijar la semilla y aplicarla a todas las posibles variaciones aleatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2713b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random # También para operaciones random de Python\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed) # Para todas las GPUs\n",
    "    torch.cuda.manual_seed_all(seed) # Para múltiples GPUs\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # Algunas operaciones de cuDNN pueden ser no deterministas, se recomienda esto:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # Puede hacer que el entrenamiento sea más lento\n",
    "\n",
    "# Definir la semilla que usaremos\n",
    "MY_SEED = 42\n",
    "set_seed(MY_SEED)\n",
    "\n",
    "# Acá empieza el código de la aplicación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9086f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import jiwer \n",
    "# Pruebitas para definir 'cer'\n",
    "reference = 'chau'\n",
    "cer_score = F.edit_distance('ciao', reference)/len(reference)\n",
    "print(cer_score)\n",
    "jcer_score = jiwer.cer(reference, 'ciao')\n",
    "print(jcer_score)\n",
    "\n",
    "# Pero en realidad en este programa uso el wer, porque el GreedyDecoder nos da las salidas en caracteres separados por blancos\n",
    "# (como si fueran palabras). Y jiwer tiene los dos, así que usamos el wer del jiwer. \n",
    "# Después sirve como excusa para ver los alineamientos. \n",
    "def cer(pred,ref):\n",
    "    return(jiwer.wer(ref, pred))\n",
    "    # return(F.edit_distance(pred, ref)/len(ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427f530",
   "metadata": {},
   "source": [
    "##### Sobre `model.train()`, `model.eval()` y `with torch.no_grad()`\n",
    "  - Usar `model.train()` cuando entrenamos para que `BatchNormalization` y `dropout` funcionen correctamente\n",
    "  - Usar `model.eval()` cuando hacemos test o validación.\n",
    "  - Usar `with torch.no_grad()` es decir no calcular el gradiente dentro de lo que esté en el bloque `with`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training mode\n",
    "model.train()\n",
    "# Your training loop\n",
    "# ...\n",
    "# Now switch to evaluation mode for validation\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():  # No gradient calculation for evaluation\n",
    "    out_data = model(data)\n",
    "\n",
    "# Don't forget to switch back to training mode!\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af162e",
   "metadata": {},
   "source": [
    "\n",
    "##### Esquema general\n",
    "  - De alguna manera generamos el dataset que consta de (tensores):\n",
    "      - (x_train, y_train)\n",
    "      - (x_valid, y_valid)\n",
    "      - (x_test, y_test)\n",
    "  - Lo convertimos en un dataset que es un wrap que permite iterar sobre los datos. Podemos hacerlo nosotros o podemos usar `TensorDataset`\n",
    "  - Convertimos el dataset en un dataloader que es una versión del dataset separada en batches. Esto lo hacemos con `DataLoader`. Si es necesario, a `DataLoader` les podemos pasar una función `collate_fn` que por ejemplo haga un padding si los datos no son todos de la misma longitud. También puede hacer un shuffle de los datos en cada epoch, lo cual es bueno en el entrenamiento. El bs de validación se puede hacer más grande ya que no necesita calcular gradientes ni hacer back propagation.\n",
    "\n",
    "  Las siguientes sentencias:\n",
    "  \n",
    "    - `loss_fn = nn.CrossEntropyLoss()`\n",
    "    - `loss_func = torch.nn.functional.cross_entropy`\n",
    "\n",
    "  Hacen lo mismo, pero loss_fn es un objeto y loss_func es una función. Es un tema de programación estructurada, las dos hacen lo mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688fd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs*2)\n",
    "test_dl = DataLoader(test_ds, batch_size=bs)\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    opt = optim.SGD(model.parameters(), lr=lr) \n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step() #for p in model.parameters(): p -= p.grad * lr\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    opt = optim.SGD(model.parameters(), lr=lr) \n",
    "    test_loss, correct = 0, 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl: # Batch de train\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step() #for p in model.parameters(): p -= p.grad * lr\n",
    "            opt.zero_grad()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                test_loss += loss_func(pred,yb).item()\n",
    "\n",
    "            correct += (pred.argmax(1) == yb).type(torch.float).sum().item()\n",
    "\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef17bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([0.1,0.7,0.3,0,0.9])\n",
    "a.argmax().type(float32) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af139cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "au = {'key': 'mbwm0_si1934', 'scored': True, 'hyp_absent': False, 'hyp_empty': False, 'num_edits': 7, \n",
    " 'num_ref_tokens': 13, 'WER': 53.84615384615385, 'insertions': 0, 'deletions': 7, 'substitutions': 0, \n",
    " 'alignment': [(...), (...), (...), (...), (...), (...), (...), (...), (...), (...), (...), (...), (...)], \n",
    " 'ref_tokens': [['sil', 'w', 'ey', 'dx', 'ah', 'l', 'ih', 'dx', 'l', 'w', 'ay', 'l', 'sil']], \n",
    " 'hyp_tokens': [['sil', 'w', 'ey', 'w', 'l', 'sil']]}\n",
    "summary = {'WER': 55.38594854019464, 'SER': 100.0, 'num_edits': 8309, 'num_scored_tokens': 15002, \n",
    "           'num_erroneous_sents': 400, 'num_scored_sents': 400, 'num_absent_sents': 0, \n",
    "           'num_ref_sents': 400, 'insertions': 191, 'deletions': 5415, \n",
    "           'substitutions': 2703, 'error_rate': 55.38594854019464}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb8e101b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WER': 53.84615384615385,\n",
       " 'SER': 100.0,\n",
       " 'num_edits': 7,\n",
       " 'num_scored_tokens': 13,\n",
       " 'num_erroneous_sents': 1,\n",
       " 'num_scored_sents': 1,\n",
       " 'num_absent_sents': 0,\n",
       " 'num_ref_sents': 1,\n",
       " 'insertions': 0,\n",
       " 'deletions': 7,\n",
       " 'substitutions': 0,\n",
       " 'error_rate': 53.84615384615385}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speechbrain\n",
    "cer_stats = speechbrain.utils.metric_stats.ErrorRateStats()\n",
    "cer_stats.append(ids=['au'], predict = au['hyp_tokens'], target = au['ref_tokens'])\n",
    "cer_stats.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72e144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.json already exists. Skipping dummy file creation.\n"
     ]
    }
   ],
   "source": [
    "# Creación  de un archivo JSON\n",
    "\n",
    "try:\n",
    "    with open('p.json', 'x') as f:\n",
    "        f.write(\"\"\"\n",
    "{\n",
    "\"mrws1_sx320\": {\n",
    "\"wav\": \"/dbase/timit/test/dr5/mrws1/sx320.wav\",\n",
    "\"duration\": 3.28325,\n",
    "\"spk_id\": \"mrws1\",\n",
    "\"phn\": \"sil dh ih n ih r ih s ih n ih sil g aa sil m ey n aa sil b iy w ih th ih n w aa sil k ih ng sil d ih s sil t ih n sil s sil\",\n",
    "\"wrd\": \"the nearest synagogue may not be within walking distance\",\n",
    "\"ground_truth_phn_ends\": \"2360 2840 3216 4511 5556 7018 7880 10440 11160 12040 13160 13960 14200 17640 18280 19160 20360 21560 23800 25320 25720 26520 27800 28825 30440 31248 32208 34130 35880 36760 37640 37960 39101 40120 40360 41640 43000 43320 44200 44440 45280 46680 49560 52480\"\n",
    "},\n",
    "} \"\"\")\n",
    "except FileExistsError:\n",
    "    print(\"p.json already exists. Skipping dummy file creation.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99be6b",
   "metadata": {},
   "source": [
    "## Creación de un greedy ctc decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def greedy_ctc_decode(emissions: torch.Tensor, blank_idx: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Performs greedy CTC decoding on a batch of log-probabilities.\n",
    "\n",
    "    Args:\n",
    "        emissions: Tensor of shape (seq_len, batch_size, num_classes)\n",
    "                   containing log-probabilities.\n",
    "        blank_idx: Index of the blank token.\n",
    "\n",
    "    Returns:\n",
    "        A list of decoded strings, one for each sequence in the batch.\n",
    "    \"\"\"\n",
    "    decoded_sequences = []\n",
    "    # Permute to (batch_size, seq_len, num_classes) for easier argmax\n",
    "    emissions = emissions.permute(1, 0, 2)\n",
    "\n",
    "    for i in range(emissions.shape[0]): # Iterate over batch\n",
    "        # Get the index of the max probability at each timestep\n",
    "        argmax_preds = emissions[i].argmax(dim=-1)\n",
    "\n",
    "        decoded_seq = []\n",
    "        last_char_idx = -1\n",
    "        for char_idx in argmax_preds:\n",
    "            if char_idx != blank_idx and (char_idx != last_char_idx or last_char_idx == blank_idx):\n",
    "                # Add if not blank and not a repeated character (unless the last was blank)\n",
    "                decoded_seq.append(char_idx.item())\n",
    "            last_char_idx = char_idx\n",
    "\n",
    "        # Convert indices to actual characters (you'll need your vocab mapping)\n",
    "        # For this example, let's assume `tokens` list is available\n",
    "        decoded_strings = [tokens[idx] for idx in decoded_seq]\n",
    "        decoded_sequences.append(\"\".join(decoded_strings))\n",
    "    return decoded_sequences\n",
    "\n",
    "# Example usage\n",
    "tokens = [\"<blank>\", \"a\", \"b\", \"c\", \" \"] # Your actual vocabulary\n",
    "blank_idx = tokens.index(\"<blank>\")\n",
    "\n",
    "# Example emissions (seq_len, batch_size, num_classes)\n",
    "# Let's say the model outputs: \"a-a-b-blank-b-c\" (where '-' is blank)\n",
    "# This should decode to \"abc\"\n",
    "emissions_example = torch.zeros(7, 1, len(tokens))\n",
    "emissions_example[0, 0, tokens.index(\"a\")] = 10\n",
    "emissions_example[1, 0, blank_idx] = 10\n",
    "emissions_example[2, 0, tokens.index(\"a\")] = 10\n",
    "emissions_example[3, 0, blank_idx] = 10\n",
    "emissions_example[4, 0, tokens.index(\"b\")] = 10\n",
    "emissions_example[5, 0, blank_idx] = 10\n",
    "emissions_example[6, 0, tokens.index(\"c\")] = 10\n",
    "\n",
    "# Add a small amount of noise to other classes to avoid all zeros in softmax\n",
    "emissions_example += torch.randn_like(emissions_example) * 0.1\n",
    "\n",
    "decoded_greedy = greedy_ctc_decode(emissions_example, blank_idx)\n",
    "print(f\"Greedy decoded: {decoded_greedy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

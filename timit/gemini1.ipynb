{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f6b1d8",
   "metadata": {},
   "source": [
    "# Código generado por gemini o copilot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d0aa74",
   "metadata": {},
   "source": [
    "## Creación de dataset y dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46311f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.json already exists. Skipping dummy file creation.\n",
      "Phoneme Vocabulary Size: 33\n",
      "Word Vocabulary Size: 23\n",
      "Speaker Vocabulary Size: 1\n",
      "\n",
      "--- Iterating through DataLoader with batch_size=2 ---\n",
      "\n",
      "Batch 1:\n",
      "  Sample IDs: ['mrws1_sx50', 'mrws1_sx320']\n",
      "  WAV Paths (first 2): ['/dbase/timit/test/dr5/mrws1/sx50.wav', '/dbase/timit/test/dr5/mrws1/sx320.wav']...\n",
      "  Durations:\n",
      "tensor([3.2320, 3.2833])\n",
      "  Speaker IDs:\n",
      "tensor([0, 0])\n",
      "  Phonemes (numerical, padded):\n",
      "tensor([[ 2, 16, 25, 30,  4,  7,  2, 19,  6,  9, 31,  4,  2, 16, 13,  2, 16,  4,\n",
      "          5,  9, 10,  4,  2, 16, 20,  2, 12, 25,  2, 16,  7,  2,  5,  4,  2,  8,\n",
      "         21, 29,  2,  3, 20,  2, 32,  9,  6,  2],\n",
      "        [ 2,  3,  4,  5,  4,  6,  4,  7,  4,  5,  4,  2,  8,  9,  2, 10, 11,  5,\n",
      "          9,  2, 12, 13, 14,  4, 15,  4,  5, 14,  9,  2, 16,  4, 17,  2, 18,  4,\n",
      "          7,  2, 19,  4,  5,  2,  7,  2,  0,  0]])\n",
      "  Phoneme Lengths (original):\n",
      "tensor([46, 44])\n",
      "  Words (numerical, padded):\n",
      "tensor([[18, 19, 20, 21,  2, 22,  0,  0,  0],\n",
      "        [ 2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
      "  Word Lengths (original):\n",
      "tensor([6, 9])\n",
      "  Phoneme Ends (padded):\n",
      "tensor([[ 2040.,  3080.,  4428.,  4720.,  5880.,  7480.,  7880.,  8600.,  9293.,\n",
      "         10680., 12040., 13000., 13953., 14680., 15640., 16680., 17348., 18200.,\n",
      "         18966., 20762., 21840., 22520., 23800., 25080., 26318., 28880., 29240.,\n",
      "         31160., 32279., 32584., 33520., 34360., 34920., 35926., 37000., 37472.,\n",
      "         38200., 39644., 42234., 42760., 43240., 44840., 45720., 48333., 49640.,\n",
      "         51680.],\n",
      "        [ 2360.,  2840.,  3216.,  4511.,  5556.,  7018.,  7880., 10440., 11160.,\n",
      "         12040., 13160., 13960., 14200., 17640., 18280., 19160., 20360., 21560.,\n",
      "         23800., 25320., 25720., 26520., 27800., 28825., 30440., 31248., 32208.,\n",
      "         34130., 35880., 36760., 37640., 37960., 39101., 40120., 40360., 41640.,\n",
      "         43000., 43320., 44200., 44440., 45280., 46680., 49560., 52480.,     0.,\n",
      "             0.]])\n",
      "  Phoneme Ends Lengths (original):\n",
      "tensor([46, 44])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "class SpeechJsonDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for reading speech data from a JSON file.\n",
    "\n",
    "    The JSON file is expected to have a top-level dictionary where keys are\n",
    "    sample IDs and values are dictionaries containing speech data attributes\n",
    "    like 'wav', 'duration', 'spk_id', 'phn', 'wrd', and 'ground_truth_phn_ends'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, json_file_path):\n",
    "        \"\"\"\n",
    "        Initializes the dataset by loading the JSON file and building vocabularies.\n",
    "\n",
    "        Args:\n",
    "            json_file_path (str): The path to the JSON dataset file.\n",
    "        \"\"\"\n",
    "        # Load the JSON data\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        # Get a list of all sample IDs (keys in the top-level dictionary)\n",
    "        self.sample_ids = list(self.data.keys())\n",
    "\n",
    "        # Build vocabularies for phonemes, words, and speaker IDs\n",
    "        self.phn_vocab = {\"<PAD>\": 0, \"<UNK>\": 1} # Start with PAD and UNK tokens\n",
    "        self.wrd_vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "        self.spk_vocab = {}\n",
    "\n",
    "        self._build_vocabularies()\n",
    "\n",
    "    def _build_vocabularies(self):\n",
    "        \"\"\"\n",
    "        Iterates through the data to build numerical vocabularies for phonemes,\n",
    "        words, and speaker IDs.\n",
    "        \"\"\"\n",
    "        phn_idx_counter = 2 # Start from 2 as 0 and 1 are reserved for PAD/UNK\n",
    "        wrd_idx_counter = 2\n",
    "        spk_idx_counter = 0\n",
    "\n",
    "        for sample_id in self.sample_ids:\n",
    "            entry = self.data[sample_id]\n",
    "\n",
    "            # Process phonemes\n",
    "            phonemes = entry.get('phn', '').split()\n",
    "            for phn in phonemes:\n",
    "                if phn not in self.phn_vocab:\n",
    "                    self.phn_vocab[phn] = phn_idx_counter\n",
    "                    phn_idx_counter += 1\n",
    "\n",
    "            # Process words\n",
    "            words = entry.get('wrd', '').split()\n",
    "            for wrd in words:\n",
    "                if wrd not in self.wrd_vocab:\n",
    "                    self.wrd_vocab[wrd] = wrd_idx_counter\n",
    "                    wrd_idx_counter += 1\n",
    "\n",
    "            # Process speaker ID\n",
    "            spk_id = entry.get('spk_id')\n",
    "            if spk_id and spk_id not in self.spk_vocab:\n",
    "                self.spk_vocab[spk_id] = spk_idx_counter\n",
    "                spk_idx_counter += 1\n",
    "\n",
    "        print(f\"Phoneme Vocabulary Size: {len(self.phn_vocab)}\")\n",
    "        print(f\"Word Vocabulary Size: {len(self.wrd_vocab)}\")\n",
    "        print(f\"Speaker Vocabulary Size: {len(self.spk_vocab)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.sample_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves a single sample from the dataset at the given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the processed data for the sample.\n",
    "                  Keys include 'sample_id', 'wav_path', 'duration',\n",
    "                  'speaker_id', 'phonemes', 'words', 'phoneme_ends'.\n",
    "        \"\"\"\n",
    "        sample_id = self.sample_ids[idx]\n",
    "        entry = self.data[sample_id]\n",
    "\n",
    "        # Extract raw data\n",
    "        wav_path = entry.get('wav', '')\n",
    "        duration = entry.get('duration', 0.0)\n",
    "\n",
    "        # Convert speaker ID to numerical\n",
    "        spk_id_str = entry.get('spk_id', '')\n",
    "        speaker_id = self.spk_vocab.get(spk_id_str, -1) # -1 for unknown speaker\n",
    "\n",
    "        # Process phonemes: tokenize and numericalize\n",
    "        phonemes_raw = entry.get('phn', '').split()\n",
    "        phonemes_numerical = [self.phn_vocab.get(p, self.phn_vocab[\"<UNK>\"]) for p in phonemes_raw]\n",
    "        # Convert to tensor; padding will be handled by collate_fn\n",
    "        phonemes_tensor = torch.tensor(phonemes_numerical, dtype=torch.long)\n",
    "\n",
    "        # Process words: tokenize and numericalize\n",
    "        words_raw = entry.get('wrd', '').split()\n",
    "        words_numerical = [self.wrd_vocab.get(w, self.wrd_vocab[\"<UNK>\"]) for w in words_raw]\n",
    "        # Convert to tensor; padding will be handled by collate_fn\n",
    "        words_tensor = torch.tensor(words_numerical, dtype=torch.long)\n",
    "\n",
    "        # Process ground_truth_phn_ends: convert to list of floats and then to tensor\n",
    "        phn_ends_raw = entry.get('ground_truth_phn_ends', '').split()\n",
    "        phoneme_ends = [float(end) for end in phn_ends_raw if end.strip()] # Ensure no empty strings\n",
    "        phoneme_ends_tensor = torch.tensor(phoneme_ends, dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            'sample_id': sample_id,\n",
    "            'wav_path': wav_path,\n",
    "            'duration': torch.tensor(duration, dtype=torch.float32),\n",
    "            'speaker_id': torch.tensor(speaker_id, dtype=torch.long),\n",
    "            'phonemes': phonemes_tensor,\n",
    "            'words': words_tensor,\n",
    "            'phoneme_ends': phoneme_ends_tensor\n",
    "        }\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable-length sequences (phonemes, words, phoneme_ends)\n",
    "    by padding them to the maximum length within each batch.\n",
    "\n",
    "    Args:\n",
    "        batch (list): A list of dictionaries, where each dictionary is a sample\n",
    "                      returned by the __getitem__ method of the dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of batched tensors and other data.\n",
    "    \"\"\"\n",
    "    # Find max lengths in the current batch for padding\n",
    "    max_phn_len = max(len(item['phonemes']) for item in batch)\n",
    "    max_wrd_len = max(len(item['words']) for item in batch)\n",
    "    max_phn_ends_len = max(len(item['phoneme_ends']) for item in batch)\n",
    "\n",
    "    padded_phonemes = []\n",
    "    padded_words = []\n",
    "    padded_phoneme_ends = []\n",
    "    sample_ids = []\n",
    "    wav_paths = []\n",
    "    durations = []\n",
    "    speaker_ids = []\n",
    "\n",
    "    for item in batch:\n",
    "        # Pad phonemes\n",
    "        phn_len = len(item['phonemes'])\n",
    "        padded_phn = torch.cat([\n",
    "            item['phonemes'],\n",
    "            torch.tensor([0] * (max_phn_len - phn_len), dtype=torch.long) # 0 is PAD_ID\n",
    "        ])\n",
    "        padded_phonemes.append(padded_phn)\n",
    "\n",
    "        # Pad words\n",
    "        wrd_len = len(item['words'])\n",
    "        padded_wrd = torch.cat([\n",
    "            item['words'],\n",
    "            torch.tensor([0] * (max_wrd_len - wrd_len), dtype=torch.long) # 0 is PAD_ID\n",
    "        ])\n",
    "        padded_words.append(padded_wrd)\n",
    "\n",
    "        # Pad phoneme ends\n",
    "        phn_ends_len = len(item['phoneme_ends'])\n",
    "        padded_pe = torch.cat([\n",
    "            item['phoneme_ends'],\n",
    "            torch.tensor([0.0] * (max_phn_ends_len - phn_ends_len), dtype=torch.float32) # 0.0 is PAD_ID\n",
    "        ])\n",
    "        padded_phoneme_ends.append(padded_pe)\n",
    "\n",
    "        # Collect other data\n",
    "        sample_ids.append(item['sample_id'])\n",
    "        wav_paths.append(item['wav_path'])\n",
    "        durations.append(item['duration'])\n",
    "        speaker_ids.append(item['speaker_id'])\n",
    "\n",
    "    return {\n",
    "        'sample_id': sample_ids, # List of strings, not a tensor\n",
    "        'wav_path': wav_paths,   # List of strings, not a tensor\n",
    "        'duration': torch.stack(durations),\n",
    "        'speaker_id': torch.stack(speaker_ids),\n",
    "        'phonemes': torch.stack(padded_phonemes),\n",
    "        'words': torch.stack(padded_words),\n",
    "        'phoneme_ends': torch.stack(padded_phoneme_ends),\n",
    "        'phoneme_lengths': torch.tensor([len(item['phonemes']) for item in batch], dtype=torch.long), # Store original lengths\n",
    "        'word_lengths': torch.tensor([len(item['words']) for item in batch], dtype=torch.long),\n",
    "        'phoneme_ends_lengths': torch.tensor([len(item['phoneme_ends']) for item in batch], dtype=torch.long)\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a dummy p.json file for demonstration if it doesn't exist\n",
    "    # In a real scenario, you would already have this file.\n",
    "    try:\n",
    "        with open('p.json', 'x') as f:\n",
    "            f.write(\"\"\"\n",
    "{\n",
    "  \"mrws1_sx320\": {\n",
    "    \"wav\": \"/dbase/timit/test/dr5/mrws1/sx320.wav\",\n",
    "    \"duration\": 3.28325,\n",
    "    \"spk_id\": \"mrws1\",\n",
    "    \"phn\": \"sil dh ih n ih r ih s ih n ih sil g aa sil m ey n aa sil b iy w ih th ih n w aa sil k ih ng sil d ih s sil t ih n sil s sil\",\n",
    "    \"wrd\": \"the nearest synagogue may not be within walking distance\",\n",
    "    \"ground_truth_phn_ends\": \"2360 2840 3216 4511 5556 7018 7880 10440 11160 12040 13160 13960 14200 17640 18280 19160 20360 21560 23800 25320 25720 26520 27800 28825 30440 31248 32208 34130 35880 36760 37640 37960 39101 40120 40360 41640 43000 43320 44200 44440 45280 46680 49560 52480\"\n",
    "  },\n",
    "  \"mrws1_sx230\": {\n",
    "    \"wav\": \"/dbase/timit/test/dr5/mrws1/sx230.wav\",\n",
    "    \"duration\": 3.2064375,\n",
    "    \"spk_id\": \"mrws1\",\n",
    "    \"phn\": \"sil ah l aw l iy w ey hh iy er sil b ah r ae sh sil n l ay z aa l eh r er z sil\",\n",
    "    \"wrd\": \"allow leeway here but rationalize all errors\",\n",
    "    \"ground_truth_phn_ends\": \"3000 3592 4600 8605 10402 12360 13618 16280 17169 18757 20469 23000 23443 24520 26402 28600 30160 30600 31400 32360 35800 36360 38809 40040 41650 42945 46120 48600 51280\"\n",
    "  },\n",
    "  \"mrws1_sx50\": {\n",
    "    \"wav\": \"/dbase/timit/test/dr5/mrws1/sx50.wav\",\n",
    "    \"duration\": 3.232,\n",
    "    \"spk_id\": \"mrws1\",\n",
    "    \"phn\": \"sil k ae dx ih s sil t r aa f ih sil k iy sil k ih n aa m ih sil k ah sil b ae sil k s sil n ih sil g l eh sil dh ah sil p aa r sil\",\n",
    "    \"wrd\": \"catastrophic economic cutbacks neglect the poor\",\n",
    "    \"ground_truth_phn_ends\": \"2040 3080 4428 4720 5880 7480 7880 8600 9293 10680 12040 13000 13953 14680 15640 16680 17348 18200 18966 20762 21840 22520 23800 25080 26318 28880 29240 31160 32279 32584 33520 34360 34920 35926 37000 37472 38200 39644 42234 42760 43240 44840 45720 48333 49640 51680\"\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "    except FileExistsError:\n",
    "        print(\"p.json already exists. Skipping dummy file creation.\")\n",
    "\n",
    "    json_file_path = 'p.json'\n",
    "\n",
    "    # 1. Create the dataset instance\n",
    "    dataset = SpeechJsonDataset(json_file_path)\n",
    "\n",
    "    # 2. Create a DataLoader instance\n",
    "    # Set batch_size and shuffle as needed for training\n",
    "    batch_size = 2\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    # 3. Iterate through the DataLoader to see the batched output\n",
    "    print(f\"\\n--- Iterating through DataLoader with batch_size={batch_size} ---\")\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        print(f\"\\nBatch {i+1}:\")\n",
    "        print(f\"  Sample IDs: {batch['sample_id']}\")\n",
    "        print(f\"  WAV Paths (first 2): {batch['wav_path'][:2]}...\")\n",
    "        print(f\"  Durations:\\n{batch['duration']}\")\n",
    "        print(f\"  Speaker IDs:\\n{batch['speaker_id']}\")\n",
    "        print(f\"  Phonemes (numerical, padded):\\n{batch['phonemes']}\")\n",
    "        print(f\"  Phoneme Lengths (original):\\n{batch['phoneme_lengths']}\")\n",
    "        print(f\"  Words (numerical, padded):\\n{batch['words']}\")\n",
    "        print(f\"  Word Lengths (original):\\n{batch['word_lengths']}\")\n",
    "        print(f\"  Phoneme Ends (padded):\\n{batch['phoneme_ends']}\")\n",
    "        print(f\"  Phoneme Ends Lengths (original):\\n{batch['phoneme_ends_lengths']}\")\n",
    "\n",
    "        # Example of how you might use these in a model:\n",
    "        # model_output = your_model(batch['phonemes'], batch['phoneme_lengths'])\n",
    "        # loss = criterion(model_output, batch['speaker_id'])\n",
    "\n",
    "        if i == 0: # Only print the first batch for brevity\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c63808",
   "metadata": {},
   "source": [
    "## Creación de un greedy ctc decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0daa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy decoded: ['aabc']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def greedy_ctc_decode(emissions: torch.Tensor, blank_idx: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Performs greedy CTC decoding on a batch of log-probabilities.\n",
    "\n",
    "    Args:\n",
    "        emissions: Tensor of shape (seq_len, batch_size, num_classes)\n",
    "                   containing log-probabilities.\n",
    "        blank_idx: Index of the blank token.\n",
    "\n",
    "    Returns:\n",
    "        A list of decoded strings, one for each sequence in the batch.\n",
    "    \"\"\"\n",
    "    decoded_sequences = []\n",
    "    # Permute to (batch_size, seq_len, num_classes) for easier argmax\n",
    "    emissions = emissions.permute(1, 0, 2)\n",
    "\n",
    "    for i in range(emissions.shape[0]): # Iterate over batch\n",
    "        # Get the index of the max probability at each timestep\n",
    "        argmax_preds = emissions[i].argmax(dim=-1)\n",
    "\n",
    "        decoded_seq = []\n",
    "        last_char_idx = -1\n",
    "        for char_idx in argmax_preds:\n",
    "            if char_idx != blank_idx and (char_idx != last_char_idx or last_char_idx == blank_idx):\n",
    "                # Add if not blank and not a repeated character (unless the last was blank)\n",
    "                decoded_seq.append(char_idx.item())\n",
    "            last_char_idx = char_idx\n",
    "\n",
    "        # Convert indices to actual characters (you'll need your vocab mapping)\n",
    "        # For this example, let's assume `tokens` list is available\n",
    "        decoded_strings = [tokens[idx] for idx in decoded_seq]\n",
    "        decoded_sequences.append(\"\".join(decoded_strings))\n",
    "    return decoded_sequences\n",
    "\n",
    "# Example usage\n",
    "tokens = [\"<blank>\", \"a\", \"b\", \"c\", \" \"] # Your actual vocabulary\n",
    "blank_idx = tokens.index(\"<blank>\")\n",
    "\n",
    "# Example emissions (seq_len, batch_size, num_classes)\n",
    "# Let's say the model outputs: \"a-a-b-blank-b-c\" (where '-' is blank)\n",
    "# This should decode to \"abc\"\n",
    "emissions_example = torch.zeros(7, 1, len(tokens))\n",
    "emissions_example[0, 0, tokens.index(\"a\")] = 10\n",
    "emissions_example[1, 0, blank_idx] = 10\n",
    "emissions_example[2, 0, tokens.index(\"a\")] = 10\n",
    "emissions_example[3, 0, blank_idx] = 10\n",
    "emissions_example[4, 0, tokens.index(\"b\")] = 10\n",
    "emissions_example[5, 0, blank_idx] = 10\n",
    "emissions_example[6, 0, tokens.index(\"c\")] = 10\n",
    "\n",
    "# Add a small amount of noise to other classes to avoid all zeros in softmax\n",
    "emissions_example += torch.randn_like(emissions_example) * 0.1\n",
    "\n",
    "decoded_greedy = greedy_ctc_decode(emissions_example, blank_idx)\n",
    "print(f\"Greedy decoded: {decoded_greedy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3c444",
   "metadata": {},
   "source": [
    "## Lectura del archivo de texto con la codificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vocab\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_vocab_from_file(filepath: str) -> Vocab:\n",
    "    \"\"\"\n",
    "    Loads a torchtext.vocab.Vocab object from a file where each line\n",
    "    contains a character and its corresponding index, separated by a space.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the vocabulary file.\n",
    "\n",
    "    Returns:\n",
    "        torchtext.vocab.Vocab: The constructed Vocab object.\n",
    "    \"\"\"\n",
    "    # OrderedDict is used to preserve the order of insertion,\n",
    "    # which is important for the indices to match your file.\n",
    "    # We'll store (token, count) pairs, where count can be dummy (e.g., 1).\n",
    "    token_counts = OrderedDict()\n",
    "\n",
    "    # Variables to store special token indices for setting default later\n",
    "    unk_token = None\n",
    "    unk_index = -1\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ')\n",
    "            if len(parts) == 2:\n",
    "                char, index_str = parts[0], parts[1]\n",
    "                try:\n",
    "                    index = int(index_str)\n",
    "                    # Store (char, 1) to build_vocab_from_iterator later\n",
    "                    token_counts[char] = 1 # The count doesn't matter much here\n",
    "                    if char == \"<unk>\": # Assuming your unknown token is named \"<unk>\"\n",
    "                        unk_token = char\n",
    "                        unk_index = index\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Skipping malformed line '{line.strip()}' - index is not an integer.\")\n",
    "            else:\n",
    "                print(f\"Warning: Skipping malformed line '{line.strip()}' - expected 'char index'.\")\n",
    "\n",
    "    # Build the vocab from the ordered dictionary of token counts\n",
    "    # This ensures that the indices in the vocab match the indices in your file.\n",
    "    vocab = Vocab(token_counts)\n",
    "\n",
    "    # Set the default index for unknown tokens if an <unk> token was found in the file\n",
    "    if unk_token is not None and unk_index != -1:\n",
    "        vocab.set_default_index(unk_index)\n",
    "    else:\n",
    "        print(\"Warning: No '<unk>' token found or its index is invalid. Default index not set.\")\n",
    "        # If no <unk> is found, lookup of unknown chars will raise an error by default.\n",
    "        # You might want to handle this case, e.g., by setting a default index to 0 or raising an error.\n",
    "\n",
    "    return vocab\n",
    "\n",
    "# --- Example Usage ---\n",
    "# 1. Create a dummy vocab file for demonstration\n",
    "dummy_vocab_content = \"\"\"<unk> 0\n",
    "<pad> 1\n",
    "a 2\n",
    "b 3\n",
    "c 4\n",
    " 5\n",
    "! 6\n",
    ". 7\n",
    "x 8\n",
    "y 9\n",
    "z 10\n",
    "\"\"\"\n",
    "with open('char_vocab.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(dummy_vocab_content)\n",
    "\n",
    "# 2. Load the vocabulary\n",
    "vocab_file_path = 'char_vocab.txt'\n",
    "my_vocab = load_vocab_from_file(vocab_file_path)\n",
    "\n",
    "print(f\"Loaded Vocab size: {len(my_vocab)}\")\n",
    "\n",
    "# Test conversions\n",
    "print(f\"Index of 'a': {my_vocab['a']}\")\n",
    "print(f\"Character at index 3: {my_vocab.lookup_token(3)}\")\n",
    "print(f\"Index of unknown character 'ñ': {my_vocab['ñ']}\") # Should return default index for <unk>\n",
    "\n",
    "# Example of using the vocab with a tokenizer\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# For character-level tokenization, a simple split by character or custom function works.\n",
    "# For simplicity, we'll just convert a string to a list of characters here.\n",
    "def char_tokenizer(text: str) -> list[str]:\n",
    "    return list(text) # Splits \"hello\" into ['h', 'e', 'l', 'l', 'o']\n",
    "\n",
    "sample_text = \"ab c!.xyz\"\n",
    "tokens = char_tokenizer(sample_text)\n",
    "indices = my_vocab(tokens)\n",
    "\n",
    "print(f\"Original text: '{sample_text}'\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Indices: {indices}\")\n",
    "\n",
    "decoded_tokens = my_vocab.lookup_tokens(indices)\n",
    "decoded_text = \"\".join(decoded_tokens)\n",
    "print(f\"Decoded tokens: {decoded_tokens}\")\n",
    "print(f\"Decoded text: '{decoded_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7130bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vocab\n",
    "import os # For creating a dummy file\n",
    "\n",
    "def load_vocab_from_phoneme_file(filepath: str) -> Vocab:\n",
    "    \"\"\"\n",
    "    Loads a torchtext.vocab.Vocab object from a file where each line\n",
    "    contains a phoneme and its corresponding index, separated by a space.\n",
    "    Assumes all necessary phonemes and indices are in the file,\n",
    "    and no out-of-vocabulary handling is needed.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the vocabulary file.\n",
    "\n",
    "    Returns:\n",
    "        torchtext.vocab.Vocab: The constructed Vocab object.\n",
    "    \"\"\"\n",
    "    phoneme_to_index_map = {}\n",
    "    max_index = -1\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ')\n",
    "            if len(parts) == 2:\n",
    "                phoneme, index_str = parts[0], parts[1]\n",
    "                try:\n",
    "                    index = int(index_str)\n",
    "                    phoneme_to_index_map[phoneme] = index\n",
    "                    if index > max_index:\n",
    "                        max_index = index\n",
    "                except ValueError:\n",
    "                    print(f\"Error: Could not parse index from line: '{line.strip()}'\")\n",
    "                    raise\n",
    "            else:\n",
    "                print(f\"Error: Malformed line (expected 'phoneme index'): '{line.strip()}'\")\n",
    "                raise\n",
    "\n",
    "    # Create the index-to-phoneme list (itos_list) based on the loaded map\n",
    "    # Initialize with None as placeholders for potentially missing indices (though your data is contiguous)\n",
    "    itos_list = [None] * (max_index + 1)\n",
    "    for phoneme, index in phoneme_to_index_map.items():\n",
    "        itos_list[index] = phoneme\n",
    "    \n",
    "    # Optional: Basic check to ensure no gaps or unassigned indices if strictness is required\n",
    "    if any(item is None for item in itos_list):\n",
    "        missing_indices = [i for i, item in enumerate(itos_list) if item is None]\n",
    "        print(f\"Warning: itos_list has unassigned indices: {missing_indices}. This might indicate gaps in your input file's indices.\")\n",
    "\n",
    "\n",
    "    # Create the Vocab object directly from the itos list\n",
    "    vocab = Vocab(itos_list=itos_list)\n",
    "    \n",
    "    # No vocab.set_default_index() needed as per your requirement of no OOV.\n",
    "    # If a phoneme not in the loaded vocab is queried, it will raise a KeyError.\n",
    "\n",
    "    return vocab\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# 1. Create a dummy vocab file for demonstration\n",
    "dummy_vocab_content = \"\"\"sil 39\n",
    "d 1\n",
    "ih 2\n",
    "jh 3\n",
    "uw 4\n",
    "iy 5\n",
    "y 6\n",
    "eh 7\n",
    "w 8\n",
    "dh 9\n",
    "ey 10\n",
    "n 11\n",
    "aw 12\n",
    "er 13\n",
    "sh 14\n",
    "ae 15\n",
    "dx 16\n",
    "t 17\n",
    "ah 18\n",
    "k 19\n",
    "m 20\n",
    "r 21\n",
    "ay 22\n",
    "aa 23\n",
    "l 24\n",
    "hh 25\n",
    "f 26\n",
    "v 27\n",
    "s 28\n",
    "ow 29\n",
    "b 30\n",
    "z 31\n",
    "th 32\n",
    "g 33\n",
    "ng 34\n",
    "p 35\n",
    "ch 36\n",
    "uh 37\n",
    "oy 38\n",
    "<blank> 0\n",
    "\"\"\"\n",
    "vocab_file_name = 'phoneme_vocab.txt'\n",
    "with open(vocab_file_name, 'w', encoding='utf-8') as f:\n",
    "    f.write(dummy_vocab_content)\n",
    "\n",
    "# 2. Load the vocabulary from the file\n",
    "try:\n",
    "    my_phoneme_vocab = load_vocab_from_phoneme_file(vocab_file_name)\n",
    "    print(f\"Vocabulary loaded successfully from {vocab_file_name}.\")\n",
    "    print(f\"Loaded Vocab size: {len(my_phoneme_vocab)}\")\n",
    "\n",
    "    # A simple \"tokenizer\" function for phoneme strings\n",
    "    def phoneme_string_to_list(text_with_phonemes: str) -> list[str]:\n",
    "        return text_with_phonemes.strip().split(' ')\n",
    "\n",
    "    # Example phoneme sequence for encoding\n",
    "    input_phonemes = \"d ih jh uw <blank> iy ah\"\n",
    "    phoneme_tokens = phoneme_string_to_list(input_phonemes)\n",
    "\n",
    "    # Encode phoneme tokens to indices\n",
    "    encoded_indices = my_phoneme_vocab(phoneme_tokens)\n",
    "    print(f\"\\nOriginal phonemes: {phoneme_tokens}\")\n",
    "    print(f\"Encoded indices: {encoded_indices}\")\n",
    "\n",
    "    # Decode indices back to phonemes\n",
    "    decoded_phonemes = my_phoneme_vocab.lookup_tokens(encoded_indices)\n",
    "    print(f\"Decoded phonemes: {decoded_phonemes}\")\n",
    "\n",
    "    # Test direct lookup\n",
    "    print(f\"\\nIndex of 'sil': {my_phoneme_vocab['sil']}\")\n",
    "    print(f\"Phoneme at index 0: {my_phoneme_vocab.lookup_token(0)}\")\n",
    "    print(f\"Index of '<blank>': {my_phoneme_vocab['<blank>']}\")\n",
    "    print(f\"Phoneme at index 39: {my_phoneme_vocab.lookup_token(39)}\")\n",
    "\n",
    "    # Demonstrate what happens with an OOV token (raises KeyError as no default is set)\n",
    "    print(\"\\nAttempting to lookup an out-of-vocabulary phoneme (will cause KeyError):\")\n",
    "    try:\n",
    "        my_phoneme_vocab['not_a_phoneme']\n",
    "    except KeyError as e:\n",
    "        print(f\"Caught expected KeyError: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Clean up the dummy file\n",
    "    if os.path.exists(vocab_file_name):\n",
    "        os.remove(vocab_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
